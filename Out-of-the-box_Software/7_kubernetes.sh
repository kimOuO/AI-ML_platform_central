# # # #!/bin/bash

# # # # =====================================================
# # # # environmental variables for central-env.common
# # # # =====================================================
# # # source ../Environmental_Variables/.env.common

# # # echo ""
# # # echo "##############################################################"
# # # echo "Download and save the GPG key :"
# # # echo ""
# # # mkdir -p /etc/apt/keyrings
# # # chmod 755 /etc/apt/keyrings

# # # curl -fsSL https://pkgs.k8s.io/core:/stable:/v1.30/deb/Release.key | sudo gpg --dearmor -o /etc/apt/keyrings/kubernetes-apt-keyring.gpg

# # # echo "##############################################################"

# # # echo ""
# # # echo "##############################################################"
# # # echo "Configure the Kubernetes APT package repository :"
# # # echo ""
# # # echo 'deb [signed-by=/etc/apt/keyrings/kubernetes-apt-keyring.gpg] https://pkgs.k8s.io/core:/stable:/v1.30/deb/ /' | sudo tee /etc/apt/sources.list.d/kubernetes.list

# # # cat /etc/apt/sources.list.d/kubernetes.list

# # # echo "##############################################################"

# # # echo ""
# # # echo "##############################################################"
# # # echo "Update apt-get :"
# # # echo ""
# # # apt-get update

# # # echo "##############################################################"

# # # echo ""
# # # echo "##############################################################"
# # # echo "Install kubelet kubeadm kubectl :"
# # # echo ""
# # # apt-get install kubelet kubeadm kubectl -y
# # # apt-mark hold kubelet kubeadm kubectl

# # # kubectl version --client 
# # # kubelet --version
# # # kubeadm version

# # # echo "##############################################################"

# # # echo ""
# # # echo "##############################################################"
# # # echo "Close swap :"
# # # echo ""
# # # swapoff -a
# # # sed -i '/\/swapfile/s/^/# /' /etc/fstab # å°‡ /swapfile é€™ä¸€è¡Œè¨»è§£èµ·ä¾†(å‰æ–¹åŠ ä¸Š '#' )
# # # sed -i '/\/swap.img/s/^/# /' /etc/fstab # å°‡ /swapfile é€™ä¸€è¡Œè¨»è§£èµ·ä¾†(å‰æ–¹åŠ ä¸Š '#' )

# # # echo "##############################################################"

# # # echo ""
# # # echo "##############################################################"
# # # echo "Init kubernetes :"
# # # echo ""
# # # kubeadm init --pod-network-cidr=10.244.0.0/16

# # # echo "##############################################################"

# # # echo ""
# # # echo "##############################################################"
# # # echo "Create K8s cluster configuration file path for root:"
# # # echo ""

# # # mkdir -p /$USER/.kube
# # # sudo cp -i /etc/kubernetes/admin.conf /$USER/.kube/config
# # # sudo chown $(id -u):$(id -g) /$USER/.kube/config

# # # echo "##############################################################"

# # # echo ""
# # # echo "##############################################################"
# # # echo "Install flannel :"
# # # echo ""
# # # kubectl apply -f https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml

# # # echo "##############################################################"

# # # echo ""
# # # echo "##############################################################"
# # # echo "Taint master node :"
# # # echo ""
# # # kubectl taint nodes --all node-role.kubernetes.io/control-plane-

# # # echo "##############################################################"

# # # echo ""
# # # echo "##############################################################"
# # # echo "Wait for node mitlab status to become Ready... :"
# # # echo ""

# # # while true; do
# # #     # ç²å–ç¯€é»çš„ç‹€æ…‹
# # #     NODE_STATUS=$(kubectl get node ubuntu -o=jsonpath='{.status.conditions[?(@.type=="Ready")].status}')

# # #     # æª¢æŸ¥ç¯€é»æ˜¯å¦è™•æ–¼ Ready ç‹€æ…‹
# # #     if [[ "${NODE_STATUS}" == "True" ]]; then
# # #         echo "Node mitlab status to be Ready "
# # #         break
# # #     else
# # #         echo "Node mitlab status not to be Ready"
# # #         # ç­‰å¾… 10 ç§’å¾Œé‡è©¦
# # #         sleep 10
# # #     fi
# # # done

# # # echo "##############################################################"

# # # echo ""
# # # echo "##############################################################"
# # # echo "Create containerd config :"
# # # echo ""

# # # mkdir -p /etc/containerd
# # # containerd config default | sudo tee /etc/containerd/config.toml > /dev/null

# # # # å®šç¾©ç›®æ¨™æª”æ¡ˆ
# # # TARGET_FILE="/etc/containerd/config.toml"

# # # # ä½¿ç”¨ sed åœ¨æŒ‡å®šè¡Œå¾Œæ’å…¥
# # # MIRROR_ENTRY="\ \ \ \ \ \ \ \ [plugins.\"io.containerd.grpc.v1.cri\".registry.configs.\"${CENTRAL_STORAGE_IP}:${HARBOR_CONTAINER_PORT}\".tls]"

# # # sed -i '/\[plugins\."io.containerd\.grpc\.v1\.cri"\.registry\.configs\]/a '"$MIRROR_ENTRY" "$TARGET_FILE"

# # # MATCH_TEXT="configs.\"${CENTRAL_STORAGE_IP}:${HARBOR_CONTAINER_PORT}\""
# # # INSERT_TEXT='\ \ \ \ \ \ \ \ \ \ insecure_skip_verify = true'
# # # sed -i '/'"$MATCH_TEXT"'/a '"$INSERT_TEXT" "$TARGET_FILE"

# # # ########
# # # MIRROR_ENTRY="\ \ \ \ \ \ \ \ [plugins.\"io.containerd.grpc.v1.cri\".registry.mirrors.\"${CENTRAL_STORAGE_IP}:${HARBOR_CONTAINER_PORT}\"]"

# # # # ä½¿ç”¨ sed åœ¨æŒ‡å®šè¡Œå¾Œæ’å…¥
# # # sed -i '/\[plugins\."io.containerd\.grpc\.v1\.cri"\.registry\.mirrors\]/a '"$MIRROR_ENTRY" "$TARGET_FILE"

# # # MATCH_TEXT="mirrors.\"${CENTRAL_STORAGE_IP}:${HARBOR_CONTAINER_PORT}\""
# # # INSERT_CONTENT="\ \ \ \ \ \ \ \ \ \ endpoint = [\"http://$CENTRAL_STORAGE_IP:$HARBOR_CONTAINER_PORT\"]"
# # # sed -i '/'"$MATCH_TEXT"'/a '"$INSERT_CONTENT" "$TARGET_FILE"

# # # # config.toml example
# # # # # configs 
# # # #       [plugins."io.containerd.grpc.v1.cri".registry.configs]
# # # #         [plugins."io.containerd.grpc.v1.cri".registry.configs."<CENTRAL_STORAGE_IP>:<IMG_MGT_CONTAINER_PORT>".tls]
# # # #           insecure_skip_verify = true
# # # # # mirrors
# # # #       [plugins."io.containerd.grpc.v1.cri".registry.mirrors]
# # # #         [plugins."io.containerd.grpc.v1.cri".registry.mirrors."<CENTRAL_STORAGE_IP>:<IMG_MGT_CONTAINER_PORT>"]
# # # #           endpoint = ["http://<CENTRAL_STORAGE_IP>:<IMG_MGT_CONTAINER_PORT>"]

# # # echo "##############################################################"

# # # echo ""
# # # echo "##############################################################"
# # # echo "Create K8s cluster configuration file path for user :"
# # # echo ""
# # # ORIGINAL_USER=$(logname)
# # # ORIGINAL_HOME=$(getent passwd "$ORIGINAL_USER" | cut -d: -f6)

# # # mkdir -p $ORIGINAL_HOME/.kube
# # # sudo cp -i /etc/kubernetes/admin.conf $ORIGINAL_HOME/.kube/config
# # # sudo chown $(id -u "$ORIGINAL_USER"):$(id -g "$ORIGINAL_USER") $ORIGINAL_HOME/.kube/config

# # # echo "##############################################################"

# # # echo ""
# # # echo "##############################################################"
# # # echo "Systemctl edit containerd :"
# # # echo ""
# # # # å®šç¾©ç›®æ¨™ override æ–‡ä»¶è·¯å¾‘
# # # OVERRIDE_FILE="/etc/systemd/system/containerd.service.d/override.conf"

# # # # å‰µå»ºç›®æ¨™ç›®éŒ„ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
# # # mkdir -p "$(dirname "$OVERRIDE_FILE")"

# # # # å‘ override æ–‡ä»¶ä¸­å¯«å…¥é…ç½®
# # # cat <<EOF > "$OVERRIDE_FILE"
# # # [Service]
# # # ExecStart=
# # # ExecStart=/usr/bin/containerd --config /etc/containerd/config.toml
# # # EOF

# # # echo "##############################################################"

# # # echo ""
# # # echo "##############################################################"
# # # echo "Restart daemon containerd and docker :"
# # # echo ""
# # # systemctl daemon-reload
# # # systemctl restart containerd
# # # systemctl restart docker

# # # echo "##############################################################"
# # #!/usr/bin/env bash

# # # =====================================================
# # # Load environmental variables for central-env.common
# # # =====================================================
# # source ../Environmental_Variables/.env.common

# # set -euo pipefail

# # # å–å¾—åŸæœ¬ç™»å…¥çš„ä½¿ç”¨è€…ï¼ˆé rootï¼‰
# # ORIGINAL_USER=${SUDO_USER:-$(logname)}
# # ORIGINAL_HOME=$(getent passwd "$ORIGINAL_USER" | cut -d: -f6)

# # echo ">>> Target kubectl user: ${ORIGINAL_USER} (${ORIGINAL_HOME})"

# # # ------------------------------------------------------------
# # # 1. Close swap
# # # ------------------------------------------------------------
# # echo ">>> [1] Disable swap"

# # swapoff -a
# # # æŠŠå¸¸è¦‹çš„ swap è¨­å®šè¨»è§£æ‰
# # sed -i '/ swap / s/^\(.*\)$/#\1/g' /etc/fstab || true
# # sed -i '/\/swapfile/s/^/# /' /etc/fstab || true
# # sed -i '/\/swap.img/s/^/# /' /etc/fstab || true

# # # ------------------------------------------------------------
# # # 2. Sysctl and kernel modules
# # # ------------------------------------------------------------
# # echo ">>> [2] Configure sysctl and kernel modules"

# # # ç¢ºä¿æ¨¡çµ„è¼‰å…¥
# # modprobe overlay || true
# # modprobe br_netfilter || true

# # # é–‹æ©Ÿè‡ªå‹•è¼‰å…¥æ¨¡çµ„
# # cat <<EOF >/etc/modules-load.d/k8s.conf
# # br_netfilter
# # overlay
# # EOF

# # # è¨­å®šç¶²è·¯ç›¸é—œ sysctl
# # cat <<EOF >/etc/sysctl.d/99-kubernetes-cri.conf
# # net.bridge.bridge-nf-call-iptables  = 1
# # net.bridge.bridge-nf-call-ip6tables = 1
# # net.ipv4.ip_forward                 = 1
# # EOF

# # sysctl --system

# # # # ------------------------------------------------------------
# # # # 3. Install containerd (if not exist)
# # # # ------------------------------------------------------------
# # # echo ">>> [3] Install containerd if needed"

# # # apt-get update -y
# # # apt-get install -y containerd

# # # å»ºç«‹é è¨­ config
# # echo ">>> Generate default containerd config"
# # /bin/mkdir -p /etc/containerd
# # containerd config default >/etc/containerd/config.toml

# # TARGET_FILE="/etc/containerd/config.toml"

# # # å•Ÿç”¨ systemd cgroupï¼Œèˆ‡ kubelet é è¨­ä¸€è‡´
# # sed -i 's/SystemdCgroup = false/SystemdCgroup = true/' "$TARGET_FILE"

# # # ------------------------------------------------------------
# # # 4. Configure containerd registry for Harbor (HTTP + insecure)
# # # ------------------------------------------------------------
# # echo ">>> [4] Configure containerd registry for Harbor (${CENTRAL_STORAGE_IP}:${HARBOR_CONTAINER_PORT})"

# # # æ’å…¥ configs (tls.insecure_skip_verify = true)
# # MIRROR_ENTRY="        [plugins.\"io.containerd.grpc.v1.cri\".registry.configs.\"${CENTRAL_STORAGE_IP}:${HARBOR_CONTAINER_PORT}\".tls]"
# # sed -i '/\[plugins\."io.containerd\.grpc\.v1\.cri"\.registry\.configs\]/a '"$MIRROR_ENTRY" "$TARGET_FILE"

# # MATCH_TEXT="configs.\"${CENTRAL_STORAGE_IP}:${HARBOR_CONTAINER_PORT}\""
# # INSERT_TEXT='          insecure_skip_verify = true'
# # sed -i '/'"$MATCH_TEXT"'/a '"$INSERT_TEXT" "$TARGET_FILE"

# # # æ’å…¥ mirrors (endpoint = ["http://IP:PORT"])
# # MIRROR_ENTRY2="        [plugins.\"io.containerd.grpc.v1.cri\".registry.mirrors.\"${CENTRAL_STORAGE_IP}:${HARBOR_CONTAINER_PORT}\"]"
# # sed -i '/\[plugins\."io.containerd\.grpc\.v1\.cri"\.registry\.mirrors\]/a '"$MIRROR_ENTRY2" "$TARGET_FILE"

# # MATCH_TEXT2="mirrors.\"${CENTRAL_STORAGE_IP}:${HARBOR_CONTAINER_PORT}\""
# # INSERT_CONTENT="          endpoint = [\"http://${CENTRAL_STORAGE_IP}:${HARBOR_CONTAINER_PORT}\"]"
# # sed -i '/'"$MATCH_TEXT2"'/a '"$INSERT_CONTENT" "$TARGET_FILE"

# # # ------------------------------------------------------------
# # # 5. systemd override for containerd
# # # ------------------------------------------------------------
# # echo ">>> [5] Configure systemd override for containerd"

# # OVERRIDE_FILE="/etc/systemd/system/containerd.service.d/override.conf"
# # mkdir -p "$(dirname "$OVERRIDE_FILE")"

# # cat <<EOF >"$OVERRIDE_FILE"
# # [Service]
# # ExecStart=
# # ExecStart=/usr/bin/containerd --config /etc/containerd/config.toml
# # EOF

# # systemctl daemon-reload
# # systemctl restart containerd

# # # ------------------------------------------------------------
# # # 6. Install Kubernetes repo & packages
# # # ------------------------------------------------------------
# # echo ">>> [6] Install Kubernetes 1.32 repository and packages"

# # mkdir -p /etc/apt/keyrings
# # chmod 755 /etc/apt/keyrings

# # curl -fsSL https://pkgs.k8s.io/core:/stable:/v1.32/deb/Release.key \
# #   | gpg --dearmor -o /etc/apt/keyrings/kubernetes-apt-keyring.gpg

# # cat <<EOF >/etc/apt/sources.list.d/kubernetes.list
# # deb [signed-by=/etc/apt/keyrings/kubernetes-apt-keyring.gpg] https://pkgs.k8s.io/core:/stable:/v1.32/deb/ /
# # EOF

# # apt-get update -y
# # apt-get install -y kubelet kubeadm kubectl
# # apt-mark hold kubelet kubeadm kubectl

# # # ------------------------------------------------------------
# # # 7. kubeadm init
# # # ------------------------------------------------------------
# # echo ">>> [7] Run kubeadm init"

# # kubeadm init --pod-network-cidr=10.244.0.0/16 --v=5

# # # ä¹‹å¾Œæ•´å€‹ script ç”¨ admin.conf ç•¶ kubeconfig
# # export KUBECONFIG=/etc/kubernetes/admin.conf

# # # è®“ control-plane ä¹Ÿèƒ½æ’å·¥ä½œè² è¼‰
# # echo ">>> Remove control-plane taint (allow scheduling on master)"
# # kubectl taint nodes --all node-role.kubernetes.io/control-plane- || true

# # # ------------------------------------------------------------
# # # 8. Install flannel CNI and wait
# # # ------------------------------------------------------------
# # echo ">>> [8] Install flannel CNI"

# # kubectl apply -f https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml

# # echo ">>> Wait for flannel pods to be Ready..."
# # while true; do
# #   READY=$(kubectl get pod -n kube-flannel -o jsonpath='{.items[*].status.containerStatuses[0].ready}' 2>/dev/null | grep -c true || true)
# #   if [[ "$READY" -ge 1 ]]; then
# #     echo ">>> flannel is Ready."
# #     break
# #   else
# #     echo ">>> flannel is still starting, retry in 10 seconds..."
# #     sleep 10
# #   fi
# # done

# # # ------------------------------------------------------------
# # # 9. Wait for node Ready
# # # ------------------------------------------------------------
# # echo ">>> [9] Wait for node to become Ready..."

# # while true; do
# #   NODE_STATUS=$(kubectl get node -o=jsonpath='{.items[0].status.conditions[?(@.type=="Ready")].status}' || echo "False")
# #   if [[ "${NODE_STATUS}" == "True" ]]; then
# #     NODE_NAME=$(kubectl get node -o=jsonpath='{.items[0].metadata.name}')
# #     echo ">>> Node ${NODE_NAME} is Ready!"
# #     break
# #   else
# #     echo ">>> Node is not Ready yet, retry in 10 seconds..."
# #     sleep 10
# #   fi
# # done

# # # ------------------------------------------------------------
# # # 10. Copy kubeconfig to original login user
# # # ------------------------------------------------------------
# # echo ">>> [10] Copy kubeconfig to original user: ${ORIGINAL_USER}"

# # mkdir -p "${ORIGINAL_HOME}/.kube"
# # cp -i /etc/kubernetes/admin.conf "${ORIGINAL_HOME}/.kube/config"
# # chown "$(id -u "$ORIGINAL_USER")":"$(id -g "$ORIGINAL_USER")" "${ORIGINAL_HOME}/.kube/config"

# # echo ">>> Copy kubeconfig to root user as well"

# # mkdir -p /root/.kube
# # cp -i /etc/kubernetes/admin.conf /root/.kube/config
# # chown root:root /root/.kube/config


# # echo "============================================================"
# # echo "Kubernetes + containerd + flannel setup is DONE."
# # echo "You can now run (as ${ORIGINAL_USER}):"
# # echo "  kubectl get nodes"
# # echo "  kubectl get pods -A"
# # echo "============================================================"
# #!/bin/bash
# set -euo pipefail

# # ============================================================
# # 0. è¼‰å…¥ç’°å¢ƒè®Šæ•¸ï¼ˆä¸»è¦æ˜¯ NFS çš„ IP / è·¯å¾‘ + Harbor è¨­å®šï¼‰
# # ============================================================
# source ../Environmental_Variables/.env.common

# # ============================================================
# # 0.1 è¨­å®šå…©å€‹ Harbor Registry
# # ============================================================
# # 1) Kubeflow ç”¨çš„ Harbor Proxy Cacheï¼ˆæ”¹å¯« ghcr.io â†’ é€™å€‹ registryï¼‰
# HARBOR_PROXY_HOST="140.118.162.139:35301"

# # 2) è¨“ç·´ç”¨ image æ‰€åœ¨çš„ Harborï¼ˆä¾‹å¦‚ 140.118.162.95:32000 é€™ç¨®ï¼‰
# TRAIN_REGISTRY_HOST="${CENTRAL_STORAGE_IP}:${HARBOR_CONTAINER_PORT}"

# # å–å¾—åŸæœ¬ç™»å…¥çš„ä½¿ç”¨è€…ï¼ˆé rootï¼‰
# ORIGINAL_USER=${SUDO_USER:-$(logname)}
# ORIGINAL_HOME=$(getent passwd "$ORIGINAL_USER" | cut -d: -f6)

# echo ">>> Target kubectl user: ${ORIGINAL_USER} (${ORIGINAL_HOME})"

# # ------------------------------------------------------------
# # 1. Disable swap
# # ------------------------------------------------------------
# echo ">>> [1] Disable swap"

# swapoff -a || true
# # æŠŠå¸¸è¦‹çš„ swap è¨­å®šè¨»è§£æ‰
# sed -i '/ swap / s/^\(.*\)$/#\1/g' /etc/fstab || true
# sed -i '/\/swapfile/s/^/# /' /etc/fstab || true
# sed -i '/\/swap.img/s/^/# /' /etc/fstab || true

# # ------------------------------------------------------------
# # 2. Sysctl and kernel modules
# # ------------------------------------------------------------
# echo ">>> [2] Configure sysctl and kernel modules"

# # ç¢ºä¿æ¨¡çµ„è¼‰å…¥
# modprobe overlay || true
# modprobe br_netfilter || true

# # é–‹æ©Ÿè‡ªå‹•è¼‰å…¥æ¨¡çµ„
# cat <<EOF >/etc/modules-load.d/k8s.conf
# br_netfilter
# overlay
# EOF

# # è¨­å®šç¶²è·¯ç›¸é—œ sysctl
# cat <<EOF >/etc/sysctl.d/99-kubernetes-cri.conf
# net.bridge.bridge-nf-call-iptables  = 1
# net.bridge.bridge-nf-call-ip6tables = 1
# net.ipv4.ip_forward                 = 1
# EOF

# sysctl --system

# # ------------------------------------------------------------
# # 3. ç”¢ç”Ÿ containerd é è¨­è¨­å®šæª” + å•Ÿç”¨ systemd cgroup
# # ------------------------------------------------------------
# echo ">>> [3] Generate default containerd config"

# mkdir -p /etc/containerd
# containerd config default >/etc/containerd/config.toml

# TARGET_FILE="/etc/containerd/config.toml"

# # å•Ÿç”¨ systemd cgroupï¼Œèˆ‡ kubelet é è¨­ä¸€è‡´
# sed -i 's/SystemdCgroup = false/SystemdCgroup = true/' "$TARGET_FILE" || true

# # ------------------------------------------------------------
# # 4. èª¿æ•´ containerd registryï¼šå•Ÿç”¨ config_pathï¼Œä¸¦ç‚ºå…©å€‹ Harbor å»º hosts.toml
# # ------------------------------------------------------------
# echo ">>> [4] Configure containerd registry for Harbor Proxy (${HARBOR_PROXY_HOST}) and Train Harbor (${TRAIN_REGISTRY_HOST})"

# # 4-1) å•Ÿç”¨ registry.config_path = "/etc/containerd/certs.d"
# # é è¨­ config æœƒæœ‰ä¸€è¡Œï¼šconfig_path = ""
# if grep -q 'config_path = ""' "$TARGET_FILE"; then
#   sed -i 's#config_path = ""#config_path = "/etc/containerd/certs.d"#' "$TARGET_FILE"
# else
#   # è‹¥æ²’æœ‰ï¼Œå‰‡åœ¨ registry å€å¡Šå¡ä¸€è¡Œï¼ˆä¸€èˆ¬ä¸æœƒèµ°åˆ°é€™è£¡ï¼Œä½†ä¿éšªä¸€ä¸‹ï¼‰
#   sed -i 's/\[plugins\."io.containerd.grpc.v1.cri"\.registry\]/[plugins."io.containerd.grpc.v1.cri".registry]\n  config_path = "\/etc\/containerd\/certs.d"/' "$TARGET_FILE"
# fi

# # ï¼ˆé‡è¦ï¼‰ä¸å†ä½¿ç”¨ registry.mirrors ä¾†è½‰ ghcr.ioï¼Œé¿å… /v2 è·¯å¾‘å°ä¸èµ·ä¾†
# # æˆ‘å€‘æ”¹ç”¨ hosts.toml ä¾†ç›´æ¥å®£å‘Šæ¯ä¸€å€‹ registryã€‚

# # 4-2) ç‚º Kubeflow Harbor Proxy å»ºç«‹ hosts.tomlï¼Œå®£å‘Šå®ƒæ˜¯ä¸€å€‹ HTTP registryï¼Œå¯ä»¥ pull / resolve
# mkdir -p "/etc/containerd/certs.d/${HARBOR_PROXY_HOST}"

# cat >"/etc/containerd/certs.d/${HARBOR_PROXY_HOST}/hosts.toml" <<EOF
# server = "http://${HARBOR_PROXY_HOST}"

# [host."http://${HARBOR_PROXY_HOST}"]
#   capabilities = ["pull", "resolve"]
#   skip_verify = true
# EOF

# # 4-3) ç‚ºã€Œè¨“ç·´ç”¨ Harborã€å»ºç«‹ hosts.tomlï¼Œè®“ç¯€é»å¯ä»¥å¾é€™è£¡æ‹‰è¨“ç·´ image
# mkdir -p "/etc/containerd/certs.d/${TRAIN_REGISTRY_HOST}"

# cat >"/etc/containerd/certs.d/${TRAIN_REGISTRY_HOST}/hosts.toml" <<EOF
# server = "http://${TRAIN_REGISTRY_HOST}"

# [host."http://${TRAIN_REGISTRY_HOST}"]
#   # å¦‚æœä¹‹å¾Œè¦å¾ç¯€é» push image ä¸Šå»ï¼Œå¯ä»¥åŠ ä¸Š "push"
#   capabilities = ["pull", "resolve"]
#   skip_verify = true
# EOF

# echo ">>> containerd registry config_path = /etc/containerd/certs.d"
# echo ">>> hosts.toml created for:"
# echo "    - ${HARBOR_PROXY_HOST} (Kubeflow Proxy Cache)"
# echo "    - ${TRAIN_REGISTRY_HOST} (Training Images Harbor)"

# # ------------------------------------------------------------
# # 5. systemd override for containerd
# # ------------------------------------------------------------
# echo ">>> [5] Configure systemd override for containerd"

# OVERRIDE_FILE="/etc/systemd/system/containerd.service.d/override.conf"
# mkdir -p "$(dirname "$OVERRIDE_FILE")"

# cat <<EOF >"$OVERRIDE_FILE"
# [Service]
# ExecStart=
# ExecStart=/usr/bin/containerd --config /etc/containerd/config.toml
# EOF

# systemctl daemon-reload
# systemctl restart containerd

# echo ">>> containerd restarted. You can verify with: crictl info | sed -n '/\"registry\"/,/\"sandboxImage\"/p'"

# # ------------------------------------------------------------
# # 6. Install Kubernetes repo & packages
# # ------------------------------------------------------------
# echo ">>> [6] Install Kubernetes 1.32 repository and packages"

# mkdir -p /etc/apt/keyrings
# chmod 755 /etc/apt/keyrings

# curl -fsSL https://pkgs.k8s.io/core:/stable:/v1.32/deb/Release.key \
#   | gpg --dearmor -o /etc/apt/keyrings/kubernetes-apt-keyring.gpg

# cat <<EOF >/etc/apt/sources.list.d/kubernetes.list
# deb [signed-by=/etc/apt/keyrings/kubernetes-apt-keyring.gpg] https://pkgs.k8s.io/core:/stable:/v1.32/deb/ /
# EOF

# apt-get update -y
# apt-get install -y kubelet kubeadm kubectl
# apt-mark hold kubelet kubeadm kubectl

# # ------------------------------------------------------------
# # 7. kubeadm init
# # ------------------------------------------------------------
# echo ">>> [7] Run kubeadm init"

# kubeadm init --pod-network-cidr=10.244.0.0/16 --v=5

# # ä¹‹å¾Œæ•´å€‹ script ç”¨ admin.conf ç•¶ kubeconfig
# export KUBECONFIG=/etc/kubernetes/admin.conf

# # è®“ control-plane ä¹Ÿèƒ½æ’å·¥ä½œè² è¼‰
# echo ">>> Remove control-plane taint (allow scheduling on master)"
# kubectl taint nodes --all node-role.kubernetes.io/control-plane- || true

# # ------------------------------------------------------------
# # 8. Install flannel CNI and wait
# # ------------------------------------------------------------
# echo ">>> [8] Install flannel CNI"

# kubectl apply -f https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml

# echo ">>> Wait for flannel pods to be Ready..."
# while true; do
#   READY=$(kubectl get pod -n kube-flannel -o jsonpath='{.items[*].status.containerStatuses[0].ready}' 2>/dev/null | grep -c true || true)
#   if [[ "$READY" -ge 1 ]]; then
#     echo ">>> flannel is Ready."
#     break
#   else
#     echo ">>> flannel is still starting, retry in 10 seconds..."
#     sleep 10
#   fi
# done

# # ------------------------------------------------------------
# # 9. Wait for node Ready
# # ------------------------------------------------------------
# echo ">>> [9] Wait for node to become Ready..."

# while true; do
#   NODE_STATUS=$(kubectl get node -o=jsonpath='{.items[0].status.conditions[?(@.type=="Ready")].status}' || echo "False")
#   if [[ "${NODE_STATUS}" == "True" ]]; then
#     NODE_NAME=$(kubectl get node -o=jsonpath='{.items[0].metadata.name}')
#     echo ">>> Node ${NODE_NAME} is Ready!"
#     break
#   else
#     echo ">>> Node is not Ready yet, retry in 10 seconds..."
#     sleep 10
#   fi
# done

# # ------------------------------------------------------------
# # 10. Copy kubeconfig to original login user + root
# # ------------------------------------------------------------
# echo ">>> [10] Copy kubeconfig to original user: ${ORIGINAL_USER}"

# mkdir -p "${ORIGINAL_HOME}/.kube"

# # å¦‚æœ ~/.kube/config è¢«èª¤å»ºæˆç›®éŒ„ï¼Œå…ˆåˆªæ‰
# if [ -d "${ORIGINAL_HOME}/.kube/config" ]; then
#   rm -rf "${ORIGINAL_HOME}/.kube/config"
# fi

# cp -i /etc/kubernetes/admin.conf "${ORIGINAL_HOME}/.kube/config"
# chown "$(id -u "$ORIGINAL_USER")":"$(id -g "$ORIGINAL_USER")" "${ORIGINAL_HOME}/.kube/config"

# echo ">>> Copy kubeconfig to root user as well"

# mkdir -p /root/.kube

# if [ -d /root/.kube/config ]; then
#   rm -rf /root/.kube/config
# fi

# cp -i /etc/kubernetes/admin.conf /root/.kube/config
# chown root:root /root/.kube/config

# echo "============================================================"
# echo "Kubernetes + containerd + flannel + TWO Harbor registries setup is DONE."
# echo "Harbor Proxy (Kubeflow images):          ${HARBOR_PROXY_HOST}"
# echo "Train Harbor (training images registry): ${TRAIN_REGISTRY_HOST}"
# echo "You can now run (as ${ORIGINAL_USER}):"
# echo "  kubectl get nodes"
# echo "  kubectl get pods -A"
# echo "============================================================"
#!/bin/bash
set -o errexit
set -o nounset
set -o pipefail

# ============================================================
# 0. è¼‰å…¥ç’°å¢ƒè®Šæ•¸
#    éœ€è¦ CENTRAL_STORAGE_IP / NFS_SERVER_PATH / HARBOR_PROXY_REGISTRY ç­‰
# ============================================================
source ../Environmental_Variables/.env.common

# Kubeflow namespaceï¼ˆé è¨­ kubeflowï¼‰
KFP_NAMESPACE="kubeflow"

# ============================================================
# 0.1 Harbor Proxy è¨­å®šï¼šæŠŠ ghcr.io æ”¹æˆ Harbor Proxy
# ============================================================
# ä¹‹å¾Œæ‰€æœ‰ kustomize build å‡ºä¾†çš„ YAMLï¼Œåªè¦æœ‰ ghcr.io/ é–‹é ­çš„ imageï¼Œ
# éƒ½æœƒè¢« rewrite æˆï¼š${HARBOR_PROXY_REGISTRY}/...
HARBOR_PROXY_REGISTRY="${HARBOR_PROXY_REGISTRY:-140.118.162.139:35301/ghcr}"

rewrite_ghcr_to_harbor() {
  # æŠŠ YAML è£¡æ‰€æœ‰ ghcr.io/... æ”¹æˆ ${HARBOR_PROXY_REGISTRY}/...
  sed "s#ghcr.io/#${HARBOR_PROXY_REGISTRY}/#g"
}

kf_apply() {
  local path="$1"
  echo "[KF+Harbor] kustomize build ${path} | rewrite_ghcr_to_harbor | kubectl apply -f -"
  kustomize build "${path}" \
    | rewrite_ghcr_to_harbor \
    | kubectl apply -f -
}

echo "##############################################################"
echo "Set NFS server for kubeflow:"
echo "##############################################################"
echo ""

# # ------------------------------------------------------------
# # 1. å®‰è£ NFS Subdir External Provisioner
# # ------------------------------------------------------------
# helm repo add nfs-subdir-external-provisioner https://kubernetes-sigs.github.io/nfs-subdir-external-provisioner

# # é€™è£¡æ”¹æˆã€Œå¯«æ­»ã€çš„ IP + è·¯å¾‘
# helm install nfs-subdir-external-provisioner nfs-subdir-external-provisioner/nfs-subdir-external-provisioner \
#   --create-namespace \
#   --namespace nfs-provisioner \
#   --set nfs.server=${CENTRAL_STORAGE_IP} \
#   --set nfs.path=${NFS_SERVER_PATH}

# # ================== è¨­å®š nfs-client ç‚ºé è¨­ StorageClassï¼Œé¿å… PVC Pending ==================
# echo "============================================================"
# echo "[NFS] è¨­å®š nfs-client ç‚ºé è¨­ StorageClassï¼Œé¿å… PVC æ²’æŒ‡å®šæ™‚å¡ Pending"
# echo "============================================================"

# # ç­‰å¾… nfs-client StorageClass å»ºç«‹ï¼ˆæœ€å¤šç­‰ 30 æ¬¡ï¼Œæ¯æ¬¡ 5 ç§’ï¼‰
# for i in {1..30}; do
#   if kubectl get sc nfs-client >/dev/null 2>&1; then
#     echo "[INFO] æ‰¾åˆ° StorageClass nfs-client"
#     break
#   fi
#   echo "[INFO] ç­‰å¾… nfs-client StorageClass å»ºç«‹ä¸­ (${i}/30)..."
#   sleep 5
# done

# # å°‡ nfs-client è¨­ç‚º default StorageClassï¼ˆè‹¥å¤±æ•—åªå° WARNINGï¼Œä¸ä¸­æ–·æ•´å€‹è…³æœ¬ï¼‰
# if kubectl get sc nfs-client >/dev/null 2>&1; then
#   kubectl patch storageclass nfs-client \
#     -p '{"metadata": {"annotations":{"storageclass.kubernetes.io/is-default-class":"true"}}}' \
#     && echo "[INFO] å·²å°‡ nfs-client è¨­ç‚ºé è¨­ StorageClass" \
#     || echo "[WARN] è¨­å®š nfs-client ç‚ºé è¨­ StorageClass å¤±æ•—ï¼Œè«‹æ‰‹å‹•æª¢æŸ¥"
# else
#   echo "[WARN] ä»ç„¶æ‰¾ä¸åˆ° StorageClass nfs-clientï¼ŒPVC å¯èƒ½æœƒå¡ Pendingï¼Œè«‹æ‰‹å‹•æª¢æŸ¥"
# fi
# # ================== NFS å€å¡ŠçµæŸ ================================================================

# echo "##############################################################"

# echo ""
# echo "##############################################################"
# echo "Build kubeflow :"
# echo "##############################################################"
# echo ""
# # ------------------------------------------------------------
# # 2. ä¸‹è¼‰ Kubeflow manifests èˆ‡ kustomize
# # ------------------------------------------------------------
# git clone https://github.com/kubeflow/manifests.git
cd manifests
# git checkout v1.10-branch
# wget https://github.com/kubernetes-sigs/kustomize/releases/download/kustomize%2Fv5.4.3/kustomize_v5.4.3_linux_amd64.tar.gz

# # Unzip kustomize and Configure kustomize
# tar -xzvf kustomize_v5.4.3_linux_amd64.tar.gz
# chmod 777 kustomize
# mv kustomize /usr/bin/kustomize

# # ------------------------------------------------------------
# # 2.5 å…ˆå»ºç«‹ kubeflow namespaceï¼ˆé¿å…å¾Œé¢ä¸€å † namespaces "kubeflow" not foundï¼‰
# # ------------------------------------------------------------
# echo "============================================================"
# echo "[2.5] å»ºç«‹ kubeflow namespace"
# echo "============================================================"

# kubectl create namespace "${KFP_NAMESPACE}" --dry-run=client -o yaml | kubectl apply -f -

# # ------------------------------------------------------------
# # 3. å®‰è£ cert-manager
# # ------------------------------------------------------------
# echo "============================================================"
# echo "[3] å®‰è£ cert-manager"
# echo "============================================================"

# 1) å…ˆå®‰è£ cert-manager æœ¬é«”
kf_apply common/cert-manager/base

# 2) ç­‰ deployment Readyï¼ˆå« webhookï¼‰
kubectl wait --for=condition=Available --timeout=300s -n cert-manager deployment/cert-manager
kubectl wait --for=condition=Available --timeout=300s -n cert-manager deployment/cert-manager-webhook
kubectl wait --for=condition=Available --timeout=300s -n cert-manager deployment/cert-manager-cainjector

# 3) å†å®‰è£ Kubeflow issuerï¼ˆé€™æ™‚ webhook å·²ç¶“ readyï¼‰
kf_apply common/cert-manager/kubeflow-issuer/base

# ------------------------------------------------------------
# 4. å®‰è£ Istio (Kubeflow é è¨­è¨­å®š)
# ------------------------------------------------------------
echo "============================================================"
echo "[4] å®‰è£ Istio (Kubeflow é è¨­è¨­å®š)"
echo "============================================================"

# Istio CRDs
kf_apply common/istio/istio-crds/base
# Istio namespace + åŸºæœ¬è¨­å®š
kf_apply common/istio/istio-namespace/base
# Istio å®‰è£ï¼ˆä½¿ç”¨ oauth2-proxy overlayï¼‰
kf_apply common/istio/istio-install/overlays/oauth2-proxy

kubectl wait --for=condition=Available --timeout=600s -n istio-system deployment/istiod
kubectl wait --for=condition=Available --timeout=600s -n istio-system deployment/istio-ingressgateway

# ------------------------------------------------------------
# 5. OAuth2-proxy + Dexï¼ˆç™»å…¥æ©Ÿåˆ¶ï¼‰
# ------------------------------------------------------------
echo "============================================================"
echo "[5] OAuth2-proxy + Dexï¼ˆç™»å…¥æ©Ÿåˆ¶ï¼‰"
echo "============================================================"

# OAuth2-proxy
kf_apply common/oauth2-proxy/overlays/m2m-dex-only/
kubectl wait --for=condition=Available --timeout=300s -n oauth2-proxy deployment/oauth2-proxy

# Dexï¼ˆé è¨­å¸³å¯†ï¼šuser@example.com / 12341234ï¼‰
kf_apply common/dex/overlays/oauth2-proxy
kubectl wait --for=condition=Available --timeout=300s -n auth deployment/dex

# ------------------------------------------------------------
# 6. NetworkPolicy + RBAC + Kubeflow çš„ Istio è³‡æº + Pipelines Core
# ------------------------------------------------------------
echo "============================================================"
echo "[6] NetworkPolicy + RBAC + Kubeflow çš„ Istio è³‡æº + Pipelines"
echo "============================================================"

# NetworkPolicy
kf_apply common/networkpolicies/base

# Kubeflow Roles (ClusterRoles / ClusterRoleBindings ç­‰)
kf_apply common/kubeflow-roles/base

# Kubeflow Istio è³‡æºï¼ˆVirtualService / Gateway ç­‰ï¼‰
kf_apply common/istio/kubeflow-istio-resources/base

# Kubeflow Pipelines (multi-user, cert-manager ç‰ˆæœ¬)
# éƒ¨åˆ†ç’°å¢ƒæœƒè·³ DecoratorController / namespace ç­‰è­¦å‘Šï¼Œä½†ä¸å½±éŸ¿å¾ŒçºŒï¼Œå¯å¿½ç•¥
set +o errexit
kf_apply applications/pipeline/upstream/env/cert-manager/platform-agnostic-multi-user || \
  echo "[WARN] Some Pipeline resources may have failed on first apply (e.g. DecoratorController). You can re-run this kustomize later if needed."
set -o errexit

# å…ˆç­‰ ml-pipeline-ui èµ·ä¾†ï¼ˆå¦‚æœé‚„æ²’å»ºæˆåŠŸæœƒ timeoutï¼Œä½†è…³æœ¬æœƒç…§è¦å‰‡ç­‰ï¼‰
kubectl wait --for=condition=Available --timeout=600s -n "${KFP_NAMESPACE}" deployment/ml-pipeline-ui || \
  echo "[WARN] ml-pipeline-ui not Ready yet. Please check later with: kubectl get pods -n ${KFP_NAMESPACE}"

# ------------------------------------------------------------
# 6.1 é—œé–‰ Kubeflow Pipelines çš„ cache webhookï¼ˆcache-webhook-kubeflowï¼‰
# ------------------------------------------------------------
echo "============================================================"
echo "[6.1] é—œé–‰ Kubeflow Pipelines çš„ cache webhookï¼ˆcache-webhook-kubeflowï¼‰"
echo "============================================================"

CACHE_WEBHOOK_NAME="cache-webhook-kubeflow"
if kubectl get mutatingwebhookconfiguration "${CACHE_WEBHOOK_NAME}" &>/dev/null; then
  echo "[INFO] Found mutatingwebhookconfiguration ${CACHE_WEBHOOK_NAME}, patching to only allow DELETE..."
  kubectl patch mutatingwebhookconfiguration "${CACHE_WEBHOOK_NAME}" \
    --type='json' \
    -p='[{"op":"replace", "path": "/webhooks/0/rules/0/operations/0", "value": "DELETE"}]'
  echo "[INFO] cache-webhook-kubeflow patched successfully."
else
  echo "[WARN] mutatingwebhookconfiguration ${CACHE_WEBHOOK_NAME} not found, skip cache webhook patch."
fi

# ------------------------------------------------------------
# 6.2 é—œé–‰ Kubeflow Pipelines ç›¸é—œ DestinationRule çš„ mTLSï¼ˆTLS â†’ DISABLEï¼‰
# ------------------------------------------------------------
echo "============================================================"
echo "[6.2] Patch Kubeflow Pipelines DestinationRule TLS = DISABLE"
echo "============================================================"

DEST_RULES=(
  ml-pipeline
  ml-pipeline-ui
  ml-pipeline-visualizationserver
  metadata-grpc-service
  ml-pipeline-minio
  ml-pipeline-mysql
)

for dr in "${DEST_RULES[@]}"; do
  if kubectl -n "${KFP_NAMESPACE}" get destinationrule "${dr}" &>/dev/null; then
    echo "  - Patching DestinationRule: ${dr}"
    kubectl -n "${KFP_NAMESPACE}" patch destinationrule "${dr}" \
      --type='json' \
      -p='[{"op":"replace","path":"/spec/trafficPolicy/tls","value":{"mode":"DISABLE"}}]'
  else
    echo "  - DestinationRule ${dr} not found, skip."
  fi
done

# ------------------------------------------------------------
# 6.3 ä¿®å¾© Kubeflow Pipelines ä½¿ç”¨çš„ MySQLï¼ˆroot å¸³è™Ÿ / plugin / DBï¼‰
# ------------------------------------------------------------
echo "============================================================"
echo "[6.3] ä¿®å¾© Kubeflow MySQL è¨­å®šï¼ˆroot plugin + metadb/mlpipeline/cachedbï¼‰"
echo "============================================================"

echo "[MySQL Fix] å°‹æ‰¾ MySQL Pod (label app=mysql, namespace=${KFP_NAMESPACE})"

MYSQL_POD=""
for i in {1..30}; do
  MYSQL_POD=$(kubectl -n "${KFP_NAMESPACE}" get pod -l app=mysql -o jsonpath='{.items[0].metadata.name}' 2>/dev/null || true)
  if [[ -n "${MYSQL_POD}" ]]; then
    PHASE=$(kubectl -n "${KFP_NAMESPACE}" get pod "${MYSQL_POD}" -o jsonpath='{.status.phase}' || echo "Unknown")
    echo "[INFO] æ‰¾åˆ° MySQL Pod: ${MYSQL_POD}, phase=${PHASE}"
    if [[ "${PHASE}" == "Running" ]]; then
      break
    fi
  else
    echo "[INFO] å°šæœªæ‰¾åˆ° MySQL Podï¼Œç­‰å¾…ä¸­ (${i}/30)..."
  fi
  sleep 5
done

if [[ -z "${MYSQL_POD}" ]]; then
  echo "[ERROR] ç„¡æ³•åœ¨ namespace=${KFP_NAMESPACE} æ‰¾åˆ° app=mysql çš„ Podï¼Œè«‹ç¢ºèª Kubeflow Pipelines æ˜¯å¦å·²å®‰è£ã€‚"
  exit 1
fi

# ğŸ”¥ æ–°å¢ï¼šç­‰å¾… mysqld çœŸçš„ Readyï¼ˆé¿å… socket é€£ä¸åˆ°ï¼‰
echo "[MySQL Fix] ç­‰å¾… mysqld readyï¼ˆmysqladmin pingï¼‰..."

MYSQL_READY=0
for i in {1..60}; do
  if kubectl -n "${KFP_NAMESPACE}" exec "${MYSQL_POD}" -- \
       sh -c "mysqladmin ping -u root --silent" >/dev/null 2>&1; then
    echo "[INFO] MySQL å·²ç¶“å°±ç·’ï¼ˆmysqld å›æ‡‰ pingï¼‰ã€‚"
    MYSQL_READY=1
    break
  fi
  echo "[INFO] MySQL å°šæœª readyï¼Œé‡è©¦ä¸­ (${i}/60)..."
  sleep 5
done

if [[ "${MYSQL_READY}" -ne 1 ]]; then
  echo "[ERROR] ç­‰å¾… mysqld è¶…æ™‚ï¼Œä»ç„¶ç„¡æ³• ping é€šï¼Œè«‹å…ˆæ‰‹å‹•æª¢æŸ¥ MySQL Pod logã€‚"
  exit 1
fi

echo "[MySQL Fix] åœ¨ MySQL ä¸­ä¿®æ­£ root å¸³è™Ÿ / plugin / å»ºç«‹ DB"

kubectl -n "${KFP_NAMESPACE}" exec "${MYSQL_POD}" -- mysql -u root << 'EOSQL'
-- =========================================================
-- èª¿æ•´ root å¸³è™Ÿï¼š
--   - root@localhost / root@'%' ä½¿ç”¨ mysql_native_password + ç©ºå¯†ç¢¼
--   - root@'%' å…è¨±å¾å…¶ä»– Pod é€£ç·š
-- =========================================================

ALTER USER IF EXISTS 'root'@'localhost' IDENTIFIED WITH mysql_native_password BY '';

CREATE USER IF NOT EXISTS 'root'@'%' IDENTIFIED WITH mysql_native_password BY '';

GRANT ALL PRIVILEGES ON *.* TO 'root'@'%' WITH GRANT OPTION;

FLUSH PRIVILEGES;

-- =========================================================
-- å»ºç«‹ Kubeflow éœ€è¦çš„ä¸‰å€‹ DBï¼ˆè‹¥ä¸å­˜åœ¨ï¼‰
--   - metadb      : çµ¦ metadata-grpc (MLMD)
--   - mlpipeline  : çµ¦ ml-pipeline / persistenceagent / scheduledworkflow
--   - cachedb     : çµ¦ cache-server
-- =========================================================
CREATE DATABASE IF NOT EXISTS metadb;
CREATE DATABASE IF NOT EXISTS mlpipeline;
CREATE DATABASE IF NOT EXISTS cachedb;
EOSQL

echo "[MySQL Fix] MySQL åˆå§‹åŒ– SQL åŸ·è¡Œå®Œæˆï¼Œæª¢æŸ¥ç•¶å‰ç‹€æ…‹ï¼š"

echo "[INFO] ä½¿ç”¨è€… plugin ç‹€æ…‹ (æ‡‰è©²çœ‹åˆ° root@'%' èˆ‡ root@'localhost' ç‚º mysql_native_password)ï¼š"
kubectl -n "${KFP_NAMESPACE}" exec "${MYSQL_POD}" -- \
  mysql -u root -e "SELECT user, host, plugin FROM mysql.user;"

echo ""
echo "[INFO] è³‡æ–™åº«åˆ—è¡¨ (æ‡‰è©²è‡³å°‘æœ‰ metadb / mlpipeline / cachedb)ï¼š"
kubectl -n "${KFP_NAMESPACE}" exec "${MYSQL_POD}" -- \
  mysql -u root -e "SHOW DATABASES;"

# ------------------------------------------------------------
# 6.4 é‡å•Ÿ Pipelines ç›¸é—œ Podï¼ˆå¥—ç”¨ DestinationRule + MySQL ä¿®å¾©ï¼‰
# ------------------------------------------------------------
echo "============================================================"
echo "[6.4] é‡å•Ÿ Kubeflow Pipelines Podsï¼ˆå¥—ç”¨ TLS è¨­å®šèˆ‡ MySQL ä¿®å¾©çµæœï¼‰"
echo "============================================================"

echo "[INFO] Restart Kubeflow Pipelines Pods to pick up new DestinationRule and MySQL settings..."
kubectl -n "${KFP_NAMESPACE}" delete pod -l application-crd-id=kubeflow-pipelines --ignore-not-found

# ------------------------------------------------------------
# 7. å®‰è£ Central Dashboard
# ------------------------------------------------------------
echo "============================================================"
echo "[7] å®‰è£ Central Dashboard"
echo "============================================================"

kf_apply applications/centraldashboard/overlays/oauth2-proxy

kubectl wait --for=condition=Available --timeout=600s -n "${KFP_NAMESPACE}" deployment/centraldashboard || \
  echo "[WARN] centraldashboard not Ready yet. Please check: kubectl get pods -n ${KFP_NAMESPACE}"

# ------------------------------------------------------------
# 8. Profiles + é è¨­ä½¿ç”¨è€… (kubeflow-user-example-com)
# ------------------------------------------------------------
echo "============================================================"
echo "[8] Profiles + é è¨­ä½¿ç”¨è€… (kubeflow-user-example-com)"
echo "============================================================"

# Profiles + KFAMï¼ˆå®‰è£ CRD / controllerï¼‰
kf_apply applications/profiles/upstream/overlays/kubeflow

# å»ºç«‹ä¸€å€‹é è¨­ Profileï¼ˆuser@example.comï¼‰
cat << 'EOF' | kubectl apply -f -
apiVersion: kubeflow.org/v1
kind: Profile
metadata:
  name: kubeflow-user-example-com
spec:
  owner:
    kind: User
    name: user@example.com
EOF

# ================== [8.1 ä¿®æ­£ç‰ˆ] åŒæ­¥ mlpipeline-minio-artifact Secret åˆ° user namespace ==================
echo "============================================================"
echo "[8.1] åŒæ­¥ mlpipeline-minio-artifact Secret åˆ° kubeflow-user-example-com"
echo "============================================================"

# å…ˆç­‰ Profile å¹«å¿™å»ºç«‹ namespace kubeflow-user-example-comï¼ˆæœ€å¤šç­‰ 30 æ¬¡ï¼Œæ¯æ¬¡ 5 ç§’ï¼‰
for i in {1..30}; do
  if kubectl get namespace kubeflow-user-example-com >/dev/null 2>&1; then
    echo "[INFO] Profile namespace kubeflow-user-example-com å·²å»ºç«‹"
    break
  fi
  echo "[INFO] ç­‰å¾… namespace kubeflow-user-example-com å»ºç«‹ä¸­ (${i}/30)..."
  sleep 5
done

if kubectl get namespace kubeflow-user-example-com >/dev/null 2>&1; then
  # ç¢ºèªåœ¨ kubeflow namespace è£¡æœ‰é€™å€‹ Secret å†è¤‡è£½
  if kubectl -n "${KFP_NAMESPACE}" get secret mlpipeline-minio-artifact >/dev/null 2>&1; then
    kubectl get secret mlpipeline-minio-artifact -n "${KFP_NAMESPACE}" -o yaml \
      | sed "s/namespace: ${KFP_NAMESPACE}/namespace: kubeflow-user-example-com/" \
      | kubectl apply -f - \
      && echo "[INFO] å·²å°‡ mlpipeline-minio-artifact Secret è¤‡è£½åˆ° kubeflow-user-example-com" \
      || echo "[WARN] è¤‡è£½ mlpipeline-minio-artifact Secret å¤±æ•—ï¼Œè«‹æ‰‹å‹•æª¢æŸ¥"
  else
    echo "[WARN] åœ¨ ${KFP_NAMESPACE} namespace æ‰¾ä¸åˆ° mlpipeline-minio-artifact Secretï¼Œç•¥éè¤‡è£½å‹•ä½œ"
  fi
else
  echo "[WARN] namespace kubeflow-user-example-com é²é²æ²’æœ‰å»ºç«‹ï¼Œç•¥é Secret è¤‡è£½ï¼Œè«‹æ‰‹å‹•æª¢æŸ¥"
fi
# ================== [8.1 ä¿®æ­£ç‰ˆå€å¡ŠçµæŸ] ================================================================

# ------------------------------------------------------------
# 9. Admission Webhookï¼ˆNotebook ç­‰è³‡æºéœ€è¦ï¼‰
# ------------------------------------------------------------
echo "============================================================"
echo "[9] Admission Webhookï¼ˆNotebook ç­‰è³‡æºéœ€è¦ï¼‰"
echo "============================================================"

kf_apply applications/admission-webhook/upstream/overlays/cert-manager

# ------------------------------------------------------------
# 10. Notebook / Volumes / PVC Viewer / Tensorboard
# ------------------------------------------------------------
echo "============================================================"
echo "[10] å®‰è£ Notebook / Volumes / PVC Viewer / Tensorboard (Web UI ç›¸é—œ)"
# ------------------------------------------------------------

# Notebook Controller
kf_apply applications/jupyter/notebook-controller/upstream/overlays/kubeflow

# Jupyter Web App
kf_apply applications/jupyter/jupyter-web-app/upstream/overlays/istio

# Volumes Web App
kf_apply applications/volumes-web-app/upstream/overlays/istio

# PVC Viewer Controller
kf_apply applications/pvcviewer-controller/upstream/base

# Tensorboard Controller
kf_apply applications/tensorboard/tensorboard-controller/upstream/overlays/kubeflow

# Tensorboards Web App
kf_apply applications/tensorboard/tensorboards-web-app/upstream/overlays/istio

echo "============================================================"
echo "[DONE] Kubeflow with Harbor Proxy (GHCR â†’ ${HARBOR_PROXY_REGISTRY}) + MySQL ä¿®å¾©æµç¨‹å®Œæˆ"
echo "============================================================"
